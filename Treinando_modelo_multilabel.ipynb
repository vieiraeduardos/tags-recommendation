{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Treinando modelo multilabel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.0 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "0973d6013fea1e6f7f2f9c6aadc5d90f95a3cc4fae2d49d683c1580432583f3b"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funções auxiliares"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "source": [
        "import numpy as np\r\n",
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "def tags_list_to_array(tags_set):\r\n",
        "  results = []\r\n",
        "  for tags in tags_set:\r\n",
        "    results.append(list(filter(None, tags.split(\";\"))))\r\n",
        "\r\n",
        "  return results\r\n",
        "\r\n",
        "def get_unique_tags_list(tags_set):\r\n",
        "\r\n",
        "  results = []\r\n",
        "  for tags in tags_set:\r\n",
        "    for tag in tags:\r\n",
        "      results.append(tag)\r\n",
        "\r\n",
        "  return list(set(results))\r\n",
        "\r\n",
        "def get_all_tags(tags_set):\r\n",
        "  results = []\r\n",
        "  for tags in tags_set:\r\n",
        "    for tag in tags:\r\n",
        "      results.append(tag)\r\n",
        "\r\n",
        "  return results\r\n",
        "\r\n",
        "def transform_array_to_binary(tags_set):\r\n",
        "  le = preprocessing.LabelEncoder()\r\n",
        "  uniques = get_unique_tags_list(dt.Tags)\r\n",
        "\r\n",
        "  le.fit(uniques)\r\n",
        "  \r\n",
        "  length = len(uniques)\r\n",
        "  results = []\r\n",
        "  for tags in tags_set:\r\n",
        "    encoder_result = le.transform(tags)\r\n",
        "\r\n",
        "    arr = np.zeros((length,), dtype=int)\r\n",
        "    for position in encoder_result:\r\n",
        "      arr[position] = 1\r\n",
        "\r\n",
        "    results.append(list(arr))\r\n",
        "  return np.array(results)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métrica de Hit ratio"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "def hitk_convert_array_to_dict(arr):\r\n",
        "  results = []\r\n",
        "\r\n",
        "  for i in range(len(arr)):\r\n",
        "    results.append(i)\r\n",
        "    results.append(arr[i])\r\n",
        "\r\n",
        "  return dict(zip(results[::2], results[1::2]))\r\n",
        "\r\n",
        "def hitk_sort_dict(x):\r\n",
        "  return sorted(x.items(), key=lambda kv: kv[1], reverse=True)\r\n",
        "\r\n",
        "def hitk_get_k_keys(x, k):\r\n",
        "  keys = []\r\n",
        "\r\n",
        "  for item in x[:k]:\r\n",
        "    key = item[0]\r\n",
        "    value = item[1]\r\n",
        "\r\n",
        "    if value > 0.5:\r\n",
        "      keys.append(item[0])\r\n",
        "\r\n",
        "  return keys\r\n",
        "\r\n",
        "def hitk_get_number_of_correct_keys(keys_from_y_true, keys_from_y_scores):\r\n",
        "  count = 0\r\n",
        "\r\n",
        "  for i in range(min(len(keys_from_y_true), len(keys_from_y_scores))):\r\n",
        "    if keys_from_y_scores[i] in keys_from_y_true:\r\n",
        "      count += 1\r\n",
        "\r\n",
        "  return count\r\n",
        "\r\n",
        "def hitk_calculate(y_true, y_scores, k = 1):\r\n",
        "  # converting from array format to dict format\r\n",
        "  y_scores = hitk_convert_array_to_dict(y_scores)\r\n",
        "  y_true = hitk_convert_array_to_dict(y_true)\r\n",
        "\r\n",
        "  print(y_true, y_scores)\r\n",
        "\r\n",
        "  # sorting dict by value\r\n",
        "  y_scores = hitk_sort_dict(y_scores)\r\n",
        "  y_true = hitk_sort_dict(y_true)\r\n",
        "\r\n",
        "  print(y_true, y_scores)\r\n",
        "\r\n",
        "  # getting k first keys from dict\r\n",
        "  keys_from_y_scores = hitk_get_k_keys(y_scores, k)\r\n",
        "  keys_from_y_true = hitk_get_k_keys(y_true, len(y_true)) \r\n",
        "\r\n",
        "  print(keys_from_y_true, keys_from_y_scores)\r\n",
        "\r\n",
        "  # process\r\n",
        "  m = hitk_get_number_of_correct_keys(keys_from_y_true, keys_from_y_scores)\r\n",
        "\r\n",
        "  # number of tags truely\r\n",
        "  ng = len(keys_from_y_true)\r\n",
        "\r\n",
        "  # number of tags recommend\r\n",
        "  nr = len(keys_from_y_scores)\r\n",
        "\r\n",
        "  print(m, ng, nr)\r\n",
        "\r\n",
        "  return m / min(ng, nr)\r\n",
        "\r\n",
        "def hitk(y_true, y_scores, k = 1):\r\n",
        "  results = []\r\n",
        "  \r\n",
        "  for i in range(len(y_true)):\r\n",
        "    value = hitk_calculate(y_true[i], y_scores[i], k = k)\r\n",
        "  \r\n",
        "    results.append(value)\r\n",
        "\r\n",
        "  return np.mean(results)\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pré processamento"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando bibliotecas"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2SaVkBjMir6",
        "outputId": "98536161-0960-43a0-f570-a4267b46d01f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando base de dados"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "source": [
        "dt = pd.read_csv(\"Blogs.csv\")\r\n",
        "\r\n",
        "dt.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9397, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "pYymyKF3uoky",
        "outputId": "af5f0962-bb28-4446-daef-8045a32aee78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertendo formato de tags de STRING para ARRAY"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "source": [
        "dt.Tags = tags_list_to_array(dt.Tags)\r\n",
        "\r\n",
        "dt.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9397, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "metadata": {
        "id": "dIX_TkqVNmjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertendo formato de tags de ARRAY de string para ARRAY binário"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "source": [
        "y = transform_array_to_binary(dt.Tags)\r\n",
        "\r\n",
        "y.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9397, 3861)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo"
      ],
      "metadata": {
        "id": "u9L5hf0gAhRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraindo embeddings das entradas "
      ],
      "metadata": {
        "id": "iHVjcpGRvDh9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "import tensorflow_hub as hub\r\n",
        "\r\n",
        "import tensorflow_text"
      ],
      "outputs": [],
      "metadata": {
        "id": "6q-1-EEhBJWt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\"\r\n",
        "embed = hub.KerasLayer(module_url, trainable=False, name='USE_Embedding')"
      ],
      "outputs": [],
      "metadata": {
        "id": "jMhnMKbiAy7J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "titles_embeddings = embed(dt.Title.apply(str).to_list())\r\n",
        "titles_embeddings = titles_embeddings.numpy()"
      ],
      "outputs": [],
      "metadata": {
        "id": "4wPxMZoMBee8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "descriptions_embeddings = embed(dt.Description.apply(str).to_list())\r\n",
        "descriptions_embeddings = descriptions_embeddings.numpy()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'embed' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-44e79f333dda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdescriptions_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDescription\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdescriptions_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescriptions_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'embed' is not defined"
          ]
        }
      ],
      "metadata": {
        "id": "VFNnLNlivuVJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "contents_embeddings = embed(dt.Content.apply(str).to_list())\r\n",
        "contents_embeddings = contents_embeddings.numpy()"
      ],
      "outputs": [],
      "metadata": {
        "id": "fkQ5KVLHwG0-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "\r\n",
        "!pip install iterative-stratification\r\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\r\n",
        "\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import precision_score\r\n",
        "from sklearn.metrics import recall_score"
      ],
      "outputs": [],
      "metadata": {
        "id": "03KBIKMFKm1d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.metrics import coverage_error\r\n",
        "from sklearn.metrics import label_ranking_average_precision_score\r\n",
        "from sklearn.metrics import label_ranking_loss"
      ],
      "outputs": [],
      "metadata": {
        "id": "5Q6Qb9NWZ1zx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "PXg9z7ZTxkzf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_model(n_inputs, n_outputs):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Dense(n_inputs * 2, activation='relu'))\r\n",
        "  model.add(Dense(100, activation='relu'))\r\n",
        "  model.add(Dense(n_outputs, activation='sigmoid'))\r\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam')\r\n",
        "  return model\r\n",
        "\r\n",
        "def evaluate_model(X, y, variable):\r\n",
        "  results = list()\r\n",
        "\r\n",
        "  n_inputs, n_outputs = X.shape[1], len(get_unique_tags_list(dt.Tags))\r\n",
        "\r\n",
        "  mskf = MultilabelStratifiedKFold(n_splits=10, shuffle=True, random_state=0)\r\n",
        "  \r\n",
        "  fold_no = 1\r\n",
        "  for train_ix, test_ix in mskf.split(X, y):\r\n",
        "    train_ix = np.array(train_ix)\r\n",
        "    test_ix = np.array(test_ix)\r\n",
        "\r\n",
        "    X_train, X_test = X[train_ix], X[test_ix]\r\n",
        "    y_train, y_test = y[train_ix], y[test_ix]\r\n",
        "    \r\n",
        "    model = get_model(n_inputs, n_outputs)\r\n",
        "    \r\n",
        "    model.fit(X_train, y_train, verbose=0, epochs=50)\r\n",
        "    \r\n",
        "    predictions = model.predict(X_test)\r\n",
        "\r\n",
        "    print(\"Multilabel ranking metrics\")\r\n",
        "\r\n",
        "    print(\"Coverage Error:\", coverage_error(y_test, predictions))\r\n",
        "    print(\"Label Ranking Average Precision:\", label_ranking_average_precision_score(y_test, predictions))\r\n",
        "    print(\"Label Ranking Loss:\", label_ranking_loss(y_test, predictions))\r\n",
        "\r\n",
        "    predictions = predictions.round()\r\n",
        "\r\n",
        "    print(\"Normal ranking metrics\")\r\n",
        "    precision = precision_score(y_test, predictions, average='weighted')\r\n",
        "    recall = recall_score(y_test, predictions, average='weighted')\r\n",
        "    f1 = f1_score(y_test, predictions, average='weighted')\r\n",
        "\r\n",
        "    results.append([precision, recall, f1, variable])\r\n",
        "\r\n",
        "    print(f'Score for fold {fold_no}: Precision of {precision}; Recall of {recall}; F1 Score of {f1}')\r\n",
        "  \r\n",
        "    fold_no += 1\r\n",
        "  \r\n",
        "  return results"
      ],
      "outputs": [],
      "metadata": {
        "id": "9SKogaYm_QrM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "\n",
        "variables = {\n",
        "    #\"Title\": titles_embeddings,\n",
        "    \"Description\": descriptions_embeddings,\n",
        "    #\"Content\": contents_embeddings\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for variable in variables.keys(): \n",
        "  print(\"Analysing variable\", variable)\n",
        "\n",
        "  # load dataset\n",
        "  X = variables[variable]\n",
        "\n",
        "  # evaluate model\n",
        "  results = evaluate_model(X, y, variable)\n",
        "\n",
        "  # summarize performance\n",
        "  results_dt = pd.DataFrame(results)\n",
        "\n",
        "  print('MeanPrecision: %.3f (%.3f); MeanRecall: %.3f (%.3f); MeanF1: %.3f (%.3f)' % (results_dt[0].mean(), results_dt[0].std(), results_dt[1].mean(), results_dt[1].std(), results_dt[2].mean(), results_dt[2].std()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysing variable Description\n",
            "Métricas de classificação de várias etiquetas\n",
            "Coverage Error: 350.931696905016\n",
            "Label Ranking Average Precision: 0.5898945259385115\n",
            "Label Ranking Loss: 0.02851307674903198\n",
            "Métricas de classificação de tradicionais\n",
            "Score for fold 1: Precision of 0.6052585057117903; Recall of 0.4669145382045479; F1 Score of 0.5143873941187559\n",
            "Métricas de classificação de várias etiquetas\n",
            "Coverage Error: 356.74179894179895\n",
            "Label Ranking Average Precision: 0.5932897159238014\n",
            "Label Ranking Loss: 0.03164898992617977\n",
            "Métricas de classificação de tradicionais\n",
            "Score for fold 2: Precision of 0.5899162377342227; Recall of 0.4754247248637675; F1 Score of 0.5094663068418248\n",
            "Métricas de classificação de várias etiquetas\n",
            "Coverage Error: 361.11689691817213\n",
            "Label Ranking Average Precision: 0.5985762140251871\n",
            "Label Ranking Loss: 0.03231151882009875\n",
            "Métricas de classificação de tradicionais\n",
            "Score for fold 3: Precision of 0.6051398204970886; Recall of 0.4564138151924411; F1 Score of 0.5041634957443464\n",
            "Métricas de classificação de várias etiquetas\n",
            "Coverage Error: 362.48617021276596\n",
            "Label Ranking Average Precision: 0.598542629495933\n",
            "Label Ranking Loss: 0.0332848006207069\n",
            "Métricas de classificação de tradicionais\n",
            "Score for fold 4: Precision of 0.6167152935391659; Recall of 0.44516540793532605; F1 Score of 0.501837739208871\n",
            "Métricas de classificação de várias etiquetas\n",
            "Coverage Error: 405.828025477707\n",
            "Label Ranking Average Precision: 0.5947657282763829\n",
            "Label Ranking Loss: 0.03966290083761779\n",
            "Métricas de classificação de tradicionais\n",
            "Score for fold 5: Precision of 0.6038546251169128; Recall of 0.4533021127135331; F1 Score of 0.5053673795605557\n",
            "Métricas de classificação de várias etiquetas\n",
            "Coverage Error: 350.1475583864119\n",
            "Label Ranking Average Precision: 0.6092055796291928\n",
            "Label Ranking Loss: 0.030685869699993103\n",
            "Métricas de classificação de tradicionais\n",
            "Score for fold 6: Precision of 0.6209609213807846; Recall of 0.47691575440266537; F1 Score of 0.5238176067784025\n",
            "Métricas de classificação de várias etiquetas\n",
            "Coverage Error: 340.0117270788913\n",
            "Label Ranking Average Precision: 0.610975781241943\n",
            "Label Ranking Loss: 0.02973379695531787\n",
            "Métricas de classificação de tradicionais\n",
            "Score for fold 7: Precision of 0.616070640591189; Recall of 0.4601803155522164; F1 Score of 0.5114162819530905\n",
            "Métricas de classificação de várias etiquetas\n",
            "Coverage Error: 367.40894568690095\n",
            "Label Ranking Average Precision: 0.6161630376029822\n",
            "Label Ranking Loss: 0.03282083263196801\n",
            "Métricas de classificação de tradicionais\n",
            "Score for fold 8: Precision of 0.6196713372888065; Recall of 0.486920556480636; F1 Score of 0.5305958857240125\n",
            "Métricas de classificação de várias etiquetas\n",
            "Coverage Error: 340.2987288135593\n",
            "Label Ranking Average Precision: 0.6079403074686603\n",
            "Label Ranking Loss: 0.029664293904397607\n",
            "Métricas de classificação de tradicionais\n",
            "Score for fold 9: Precision of 0.6285428607147966; Recall of 0.4674970597669197; F1 Score of 0.5224323810506082\n",
            "Métricas de classificação de várias etiquetas\n",
            "Coverage Error: 344.61310782241014\n",
            "Label Ranking Average Precision: 0.6006924001679581\n",
            "Label Ranking Loss: 0.031073506851836373\n",
            "Métricas de classificação de tradicionais\n",
            "Score for fold 10: Precision of 0.594360251583064; Recall of 0.4576352577099562; F1 Score of 0.5049648803872566\n",
            "MeanPrecision: 0.610 (0.012); MeanRecall: 0.465 (0.013); MeanF1: 0.513 (0.010)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4x1SF6uEcl-",
        "outputId": "194b907b-a6e2-43b9-a288-e7c7a70e62f0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pd.DataFrame(results).to_csv(\"Results.csv\")\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('Results.csv') "
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  "
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": "download(\"download_6514ea07-4a9d-400d-9aca-be8e13a445cb\", \"Results.csv\", 2287)"
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9nFhQtm3Hi2d",
        "outputId": "2f7186b2-3b78-43a1-d74e-2cc6cd4e97ee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "results = pd.read_csv(\"Results.csv\", index_col=0)\n",
        "\n",
        "results.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fksRUCwxz_b",
        "outputId": "0c57edca-33e4-4cf9-ba0d-690dd3c86465"
      }
    }
  ]
}